{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e817d7b0",
   "metadata": {},
   "source": [
    "#### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7a7bc7",
   "metadata": {},
   "source": [
    "TensorFlow and Keras are essential for building the CNN model.\n",
    "Requests and BeautifulSoup4 are for scraping images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085de552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programdata\\anaconda3\\lib\\site-packages (2.15.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: keras in c:\\programdata\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.60.0)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.26.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7480d290",
   "metadata": {},
   "source": [
    "#### Step 2: Scrape Images of Nicholas Cage and Another person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c64a350",
   "metadata": {},
   "source": [
    "Will use Web scaper to collect images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc729e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.16.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.23.2)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b604f5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver-manager in c:\\programdata\\anaconda3\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (22.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0d6e9792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37bdf858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def scrape_images(query, num_images=500, save_dir=\"images\"):\n",
    "    # Creating the directory if it doesn't exist\n",
    "    create_directory(save_dir)\n",
    "\n",
    "    image_urls = []\n",
    "    start = 0\n",
    "    while len(image_urls) < num_images:\n",
    "        # Google Images URL with pagination\n",
    "        url = f\"https://www.google.com/search?q={query}&tbm=isch&start={start}\"\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Finding all image elements\n",
    "        for img_tag in soup.find_all(\"img\"):\n",
    "            src = img_tag.get(\"src\")\n",
    "            if src and \"http\" in src:\n",
    "                image_urls.append(src)\n",
    "                if len(image_urls) >= num_images:\n",
    "                    break\n",
    "\n",
    "        # Breaking the loop if the desired number of images is reached\n",
    "        if len(image_urls) >= num_images:\n",
    "            break\n",
    "\n",
    "        # Increment the start value for the next page\n",
    "        start += 20  # Google usually returns 20 results per page\n",
    "\n",
    "    # Downloading images\n",
    "    for i, img_url in enumerate(image_urls):\n",
    "        try:\n",
    "            img_data = requests.get(img_url).content\n",
    "            with open(os.path.join(save_dir, f\"{query.replace(' ', '_')}_{i}.jpg\"), \"wb\") as handler:\n",
    "                handler.write(img_data)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not download {img_url}. Error: {e}\")\n",
    "\n",
    "# Scrape images for Nicolas Cage\n",
    "scrape_images(\"Nicolas Cage\", save_dir=\"images/Nicolas_Cage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9e1a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here l want to split my dataset into train and testing set\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def split_images(source_dir, train_dir, test_dir, split_ratio=0.8):\n",
    "    create_directory(train_dir)\n",
    "    create_directory(test_dir)\n",
    "\n",
    "    all_images = [f for f in os.listdir(source_dir) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    \n",
    "    # Shuffling the images to ensure random splitting\n",
    "    random.shuffle(all_images)\n",
    "    \n",
    "    # Calculating the number of images for training and testing\n",
    "    split_index = int(len(all_images) * split_ratio)\n",
    "    \n",
    "    # Splitting the images into training and testing sets\n",
    "    train_images = all_images[:split_index]\n",
    "    test_images = all_images[split_index:]\n",
    "    \n",
    "    # Moving the images to their respective directories\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(source_dir, img), os.path.join(train_dir, img))\n",
    "    \n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(source_dir, img), os.path.join(test_dir, img))\n",
    "\n",
    "# Defining paths\n",
    "source_directory = \"images/Nicolas_Cage\"\n",
    "train_directory = \"images/Nicolas_Cage/train\"\n",
    "test_directory = \"images/Nicolas_Cage/test\"\n",
    "\n",
    "# Splitting the images\n",
    "split_images(source_directory, train_directory, test_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff2b658",
   "metadata": {},
   "source": [
    "#### Step 3: Build CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24671cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c46a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n",
      "Found 104 images belonging to 2 classes.\n",
      "Training Set: 416 images\n",
      "Test Set: 104 images\n"
     ]
    }
   ],
   "source": [
    "# Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\0022491\\Desktop\\IIE VARSITY COLLEGE\\2024\\Semester 2\\ICE TASK\\images\\Nicolas_Cage\\train',\n",
    "        target_size=(128,128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        r'C:\\Users\\0022491\\Desktop\\IIE VARSITY COLLEGE\\2024\\Semester 2\\ICE TASK\\images\\Nicolas_Cage\\test',\n",
    "        target_size=(128,128),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "# Print counts to verify\n",
    "print(f'Training Set: {len(training_set.filenames)} images')\n",
    "print(f'Test Set: {len(test_set.filenames)} images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2bb6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))  # 2 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb823700",
   "metadata": {},
   "source": [
    "#### Step 4: Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205f0d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 [==============================] - 7s 441ms/step - loss: 0.6773 - accuracy: 0.9279 - val_loss: 0.2277 - val_accuracy: 0.9615\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 4s 315ms/step - loss: 0.2089 - accuracy: 0.9615 - val_loss: 0.1863 - val_accuracy: 0.9615\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 4s 317ms/step - loss: 0.1780 - accuracy: 0.9615 - val_loss: 0.1958 - val_accuracy: 0.9615\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 4s 318ms/step - loss: 0.1701 - accuracy: 0.9615 - val_loss: 0.1933 - val_accuracy: 0.9615\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 5s 351ms/step - loss: 0.1642 - accuracy: 0.9615 - val_loss: 0.1926 - val_accuracy: 0.9615\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 5s 385ms/step - loss: 0.1660 - accuracy: 0.9615 - val_loss: 0.2025 - val_accuracy: 0.9615\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 5s 412ms/step - loss: 0.1625 - accuracy: 0.9615 - val_loss: 0.2013 - val_accuracy: 0.9615\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 5s 386ms/step - loss: 0.1641 - accuracy: 0.9615 - val_loss: 0.2130 - val_accuracy: 0.9615\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 5s 402ms/step - loss: 0.1600 - accuracy: 0.9615 - val_loss: 0.2839 - val_accuracy: 0.9615\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 5s 390ms/step - loss: 0.1489 - accuracy: 0.9615 - val_loss: 0.2409 - val_accuracy: 0.9615\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    training_set,\n",
    "    epochs=10,\n",
    "    validation_data=test_set,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08577c4d",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb96ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 75ms/step - loss: 0.2409 - accuracy: 0.9615\n",
      "Test Loss: 0.24091988801956177\n",
      "Test Accuracy: 0.9615384340286255\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_set, verbose=1)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9549e7",
   "metadata": {},
   "source": [
    "#####  Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dce239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicted Class: Nicolas Cage\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) \n",
    "    img_array /= 255.0  \n",
    "    predictions = model.predict(img_array)\n",
    "    class_labels = ['Nicolas Cage', 'Tom Cruise']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    return predicted_class\n",
    "\n",
    "predicted = predict_image(r'C:\\Users\\0022491\\Desktop\\IIE VARSITY COLLEGE\\2024\\Semester 2\\ICE TASK\\images\\predict\\Nicolas_Cage_20.jpg')\n",
    "print(f'Predicted Class: {predicted}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d80fbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicted Class: Nicolas Cage\n"
     ]
    }
   ],
   "source": [
    "#Another person\n",
    "another_person = predict_image(r'C:\\Users\\0022491\\Desktop\\IIE VARSITY COLLEGE\\2024\\Semester 2\\ICE TASK\\images\\Tom_Cruise\\Tom Cruise_17.jpg')\n",
    "print(f'Predicted Class: {another_person}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fddaa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Random Image Path: C:\\Users\\0022491\\Desktop\\IIE VARSITY COLLEGE\\2024\\Semester 2\\ICE TASK\\images\\predict\\Nicolas_Cage_127.jpg\n",
      "Predicted Class: Nicolas Cage\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "def predict_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) \n",
    "    img_array /= 255.0  \n",
    "    predictions = model.predict(img_array)\n",
    "    class_labels = ['Nicolas Cage']\n",
    "    predicted_class = class_labels[np.argmax(predictions)]\n",
    "    return predicted_class\n",
    "\n",
    "def predict_random_image(folder_path):\n",
    "    # List all files in the folder\n",
    "    images = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    # Select a random image\n",
    "    random_image = random.choice(images)\n",
    "    img_path = os.path.join(folder_path, random_image)\n",
    "    \n",
    "    # Predict the class of the random image\n",
    "    predicted_class = predict_image(img_path)\n",
    "    return img_path, predicted_class\n",
    "\n",
    "# Example usage\n",
    "folder_path = r'C:\\Users\\0022491\\Desktop\\IIE VARSITY COLLEGE\\2024\\Semester 2\\ICE TASK\\images\\predict'\n",
    "img_path, predicted = predict_random_image(folder_path)\n",
    "print(f'Random Image Path: {img_path}')\n",
    "print(f'Predicted Class: {predicted}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d7aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
